package vm

import (
	"context"
	"fmt"
	"io/ioutil"
	"os"
	"path/filepath"
	"strings"
	"time"

	"google.golang.org/api/compute/v1"

	"github.com/0x00fafa/gke-image-cache-builder/internal/scripts"
	"github.com/0x00fafa/gke-image-cache-builder/pkg/gcp"
	"github.com/0x00fafa/gke-image-cache-builder/pkg/log"
)

// getAutoGeneratedSSHKey reads the auto-generated SSH public key from the default location
func (m *Manager) getAutoGeneratedSSHKey() (string, error) {
	// Find SSH key path
	homeDir, err := os.UserHomeDir()
	if err != nil {
		return "", fmt.Errorf("failed to get user home directory: %w", err)
	}

	sshDir := filepath.Join(homeDir, ".ssh")
	keyPath := filepath.Join(sshDir, "id_rsa.pub")

	// Check if the file exists
	if _, err := os.Stat(keyPath); os.IsNotExist(err) {
		// If id_rsa.pub doesn't exist, try other common key types
		alternateKeys := []string{"id_ecdsa.pub", "id_ed25519.pub"}
		for _, altKey := range alternateKeys {
			altPath := filepath.Join(sshDir, altKey)
			if _, err := os.Stat(altPath); err == nil {
				keyPath = altPath
				break
			}
		}

		// If none of the files exist, return empty string
		if _, err := os.Stat(keyPath); os.IsNotExist(err) {
			return "", nil
		}
	}

	// Read the public key file
	keyData, err := ioutil.ReadFile(keyPath)
	if err != nil {
		return "", fmt.Errorf("failed to read SSH public key file: %w", err)
	}

	return strings.TrimSpace(string(keyData)), nil
}

// Manager handles VM lifecycle operations with real GCP API calls
type Manager struct {
	gcpClient *gcp.Client
	logger    *log.Logger
}

// NewManager creates a new VM manager
func NewManager(gcpClient *gcp.Client, logger *log.Logger) *Manager {
	return &Manager{
		gcpClient: gcpClient,
		logger:    logger,
	}
}

// CreateVM creates a new VM instance
func (m *Manager) CreateVM(ctx context.Context, config *Config) (*Instance, error) {
	m.logger.Infof("Creating VM: %s in zone: %s", config.Name, config.Zone)

	// Prepare metadata items
	metadataItems := []*compute.MetadataItems{}

	// Add SSH key if provided
	if config.SSHPublicKey != "" {
		// Format SSH key properly for GCP
		// GCP expects: "username:ssh-rsa AAAAB3NzaC1yc2E... user@host"
		sshKey := config.SSHPublicKey
		if !strings.Contains(sshKey, ":") {
			// Use "abc" as the username as requested
			sshKey = "abc:" + sshKey
		}
		metadataItems = append(metadataItems, &compute.MetadataItems{
			Key:   "ssh-keys",
			Value: &sshKey,
		})
	}

	// Add auto-generated SSH key if available
	autoSSHKey, err := m.getAutoGeneratedSSHKey()
	if err != nil {
		m.logger.Warnf("Failed to read auto-generated SSH key: %v", err)
	} else if autoSSHKey != "" {
		// Format SSH key properly for GCP
		// GCP expects: "username:ssh-rsa AAAAB3NzaC1yc2E... user@host"
		formattedKey := autoSSHKey
		if !strings.Contains(autoSSHKey, ":") {
			// Use "abc" as the username as requested
			formattedKey = "abc:" + autoSSHKey
		}

		// If we already have an SSH key from config, append the auto-generated one
		found := false
		for _, item := range metadataItems {
			if item.Key == "ssh-keys" {
				// Append the auto-generated key to the existing one
				existingKeys := *item.Value
				combinedKeys := existingKeys + "\n" + formattedKey
				item.Value = &combinedKeys
				found = true
				break
			}
		}

		// If no SSH key was provided in config, add the auto-generated one
		if !found {
			metadataItems = append(metadataItems, &compute.MetadataItems{
				Key:   "ssh-keys",
				Value: &formattedKey,
			})
		}
	}

	// Also add the setup script as a metadata item so we can retrieve it via SSH later
	setupScript := scripts.GetSetupScript()
	metadataItems = append(metadataItems, &compute.MetadataItems{
		Key:   "setup-script",
		Value: &setupScript,
	})

	// Add startup script to initialize the system environment automatically
	startupScript := `#!/bin/bash
# Startup script to initialize the VM environment
set -e

# Download the setup script from metadata
curl -H "Metadata-Flavor: Google" http://metadata.google.internal/computeMetadata/v1/instance/attributes/setup-script > /tmp/setup-and-verify.sh
chmod +x /tmp/setup-and-verify.sh

# Run system setup
/tmp/setup-and-verify.sh setup

# Setup containerd
/tmp/setup-and-verify.sh setup-containerd

# Create a flag file to indicate environment is ready
touch /tmp/environment_ready.flag
echo "Environment setup completed." > /tmp/environment_ready.flag

# Also create a more specific flag
echo "Full environment is ready and containerd is running" > /tmp/containerd_ready.flag
`
	metadataItems = append(metadataItems, &compute.MetadataItems{
		Key:   "startup-script",
		Value: &startupScript,
	})

	instance := &compute.Instance{
		Name:        config.Name,
		MachineType: fmt.Sprintf("projects/%s/zones/%s/machineTypes/%s", m.gcpClient.ProjectName(), config.Zone, config.MachineType),
		Zone:        config.Zone,
		Disks: []*compute.AttachedDisk{
			{
				Boot:       true,
				AutoDelete: true,
				InitializeParams: &compute.AttachedDiskInitializeParams{
					SourceImage: "projects/ubuntu-os-cloud/global/images/ubuntu-minimal-2204-jammy-v20250723",
					DiskSizeGb:  20,
					DiskType:    fmt.Sprintf("projects/%s/zones/%s/diskTypes/pd-standard", m.gcpClient.ProjectName(), config.Zone),
				},
			},
		},
		NetworkInterfaces: []*compute.NetworkInterface{
			{
				Network: fmt.Sprintf("projects/%s/global/networks/%s", m.gcpClient.ProjectName(), config.Network),
				Subnetwork: fmt.Sprintf("projects/%s/regions/%s/subnetworks/%s",
					m.gcpClient.ProjectName(), m.getRegionFromZone(config.Zone), config.Subnet),
				AccessConfigs: []*compute.AccessConfig{
					{
						Type: "ONE_TO_ONE_NAT",
						Name: "External NAT",
					},
				},
			},
		},
		ServiceAccounts: []*compute.ServiceAccount{
			{
				Email: config.ServiceAccount,
				Scopes: []string{
					"https://www.googleapis.com/auth/cloud-platform",
				},
			},
		},
		Metadata: &compute.Metadata{
			Items: metadataItems,
		},
		Scheduling: &compute.Scheduling{
			Preemptible: config.Preemptible,
		},
		Tags: &compute.Tags{
			Items: []string{"gke-image-cache-builder"},
		},
	}

	operation, err := m.gcpClient.Compute().Instances.Insert(m.gcpClient.ProjectName(), config.Zone, instance).Context(ctx).Do()
	if err != nil {
		return nil, fmt.Errorf("failed to create VM: %w", err)
	}

	// Wait for operation to complete
	if err := m.gcpClient.WaitForOperation(ctx, operation, config.Zone); err != nil {
		return nil, fmt.Errorf("VM creation operation failed: %w", err)
	}

	// Wait for VM to be running
	if err := m.waitForVMRunning(ctx, config.Name, config.Zone); err != nil {
		return nil, fmt.Errorf("VM failed to start: %w", err)
	}

	// Get the VM instance to retrieve network information
	vmInstance, err := m.gcpClient.GetInstance(ctx, config.Zone, config.Name)
	if err != nil {
		m.logger.Warnf("Failed to get VM instance details: %v", err)
	} else {
		// Print the public IP address and SSH connection info
		if len(vmInstance.NetworkInterfaces) > 0 && len(vmInstance.NetworkInterfaces[0].AccessConfigs) > 0 {
			publicIP := vmInstance.NetworkInterfaces[0].AccessConfigs[0].NatIP
			if publicIP != "" {
				m.logger.Infof("VM public IP address: %s", publicIP)
				m.logger.Infof("SSH connection command: ssh abc@%s", publicIP)
			}
		}
	}

	m.logger.Successf("VM created successfully: %s", config.Name)

	return &Instance{
		Name: config.Name,
		Zone: config.Zone,
	}, nil
}

// DeleteVM deletes a VM instance
func (m *Manager) DeleteVM(ctx context.Context, name, zone string) error {
	m.logger.Infof("Deleting VM: %s", name)

	operation, err := m.gcpClient.Compute().Instances.Delete(m.gcpClient.ProjectName(), zone, name).Context(ctx).Do()
	if err != nil {
		return fmt.Errorf("failed to delete VM: %w", err)
	}

	// Wait for operation to complete
	if err := m.gcpClient.WaitForOperation(ctx, operation, zone); err != nil {
		return fmt.Errorf("VM deletion operation failed: %w", err)
	}

	m.logger.Successf("VM deleted successfully: %s", name)
	return nil
}

// SetupVM executes the setup script on the VM (for local mode)
func (m *Manager) SetupVM(ctx context.Context, instance *Instance) error {
	m.logger.Infof("Setting up VM: %s", instance.Name)

	// For local mode, execute the script directly
	if err := scripts.ExecuteSetupScript(); err != nil {
		return fmt.Errorf("failed to setup VM: %w", err)
	}

	m.logger.Infof("VM setup completed: %s", instance.Name)
	return nil
}

// ExecuteRemoteImageBuild executes image build on remote VM
func (m *Manager) ExecuteRemoteImageBuild(ctx context.Context, instance *Instance, config *RemoteBuildConfig) error {
	m.logger.Infof("Executing remote image build on VM: %s", instance.Name)

	// Monitor the VM's serial console output for completion
	return m.monitorRemoteExecution(ctx, instance.Name, instance.Zone, config.Timeout)
}

// ValidatePermissions validates GCP permissions
func (m *Manager) ValidatePermissions(ctx context.Context, projectName, zone string) error {
	m.logger.Debug("Validating GCP permissions...")

	// Test basic compute permissions by trying to list instances
	_, err := m.gcpClient.Compute().Instances.List(projectName, zone).Context(ctx).Do()
	if err != nil {
		return fmt.Errorf("insufficient GCP permissions: %w", err)
	}

	// Test disk permissions
	_, err = m.gcpClient.Compute().Disks.List(projectName, zone).Context(ctx).Do()
	if err != nil {
		return fmt.Errorf("insufficient disk permissions: %w", err)
	}

	// Test image permissions
	_, err = m.gcpClient.Compute().Images.List(projectName).Context(ctx).Do()
	if err != nil {
		return fmt.Errorf("insufficient image permissions: %w", err)
	}

	m.logger.Debug("GCP permissions validated successfully")
	return nil
}

// waitForVMRunning waits for VM to be in RUNNING state
func (m *Manager) waitForVMRunning(ctx context.Context, instanceName, zone string) error {
	timeout := time.After(5 * time.Minute)
	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-timeout:
			return fmt.Errorf("timeout waiting for VM to start")
		case <-ticker.C:
			instance, err := m.gcpClient.GetInstance(ctx, zone, instanceName)
			if err != nil {
				continue
			}
			if instance.Status == "RUNNING" {
				return nil
			}
			m.logger.Debugf("VM status: %s, waiting...", instance.Status)
		}
	}
}

// monitorRemoteExecution monitors remote execution via serial console
func (m *Manager) monitorRemoteExecution(ctx context.Context, instanceName, zone string, timeout time.Duration) error {
	m.logger.Info("Monitoring remote execution...")

	timeoutCtx, cancel := context.WithTimeout(ctx, timeout)
	defer cancel()

	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-timeoutCtx.Done():
			return fmt.Errorf("remote execution timeout")
		case <-ticker.C:
			// Check serial console output for completion signal
			output, err := m.getSerialConsoleOutput(ctx, instanceName, zone)
			if err != nil {
				m.logger.Debugf("Failed to get serial console output: %v", err)
				continue
			}

			if strings.Contains(output, "Unpacking is completed.") {
				m.logger.Success("Remote execution completed successfully")
				return nil
			}

			if strings.Contains(output, "ERROR") || strings.Contains(output, "FAILED") {
				return fmt.Errorf("remote execution failed, check VM logs")
			}
		}
	}
}

// GetSerialConsoleOutput gets the serial console output from VM (public method)
func (m *Manager) GetSerialConsoleOutput(ctx context.Context, instanceName, zone string) (string, error) {
	output, err := m.gcpClient.Compute().Instances.GetSerialPortOutput(
		m.gcpClient.ProjectName(), zone, instanceName).Context(ctx).Do()
	if err != nil {
		return "", err
	}
	return output.Contents, nil
}

// getSerialConsoleOutput gets the serial console output from VM (private method for backward compatibility)
func (m *Manager) getSerialConsoleOutput(ctx context.Context, instanceName, zone string) (string, error) {
	return m.GetSerialConsoleOutput(ctx, instanceName, zone)
}

// getRegionFromZone extracts region from zone name
func (m *Manager) getRegionFromZone(zone string) string {
	parts := strings.Split(zone, "-")
	if len(parts) >= 2 {
		return strings.Join(parts[:2], "-")
	}
	return zone
}

// Config holds VM configuration
type Config struct {
	Name            string
	Zone            string
	MachineType     string
	Network         string
	Subnet          string
	ServiceAccount  string
	Preemptible     bool
	ContainerImages []string
	ImagePullAuth   string
	SSHPublicKey    string
}

// RemoteBuildConfig holds remote build configuration
type RemoteBuildConfig struct {
	DeviceName      string
	AuthMechanism   string
	StoreChecksums  bool
	ContainerImages []string
	Timeout         time.Duration
}

// Instance represents a VM instance
type Instance struct {
	Name string
	Zone string
}
